{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "with open(\"base.yaml\", \"r\") as f:\n",
    "    base_config = yaml.safe_load(f)\n",
    "\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)['config']\n",
    "\n",
    "merged_config = {**base_config, **config}\n",
    "\n",
    "optional_args = [\n",
    "    'cache_dir', 'checkpoints_total_limit', 'dataset_config_name', 'hub_model_id', 'hub_token',\n",
    "    'max_train_samples', 'prediction_type', 'revision', 'snr_gamma', 'train_data_dir', 'variant'\n",
    "]\n",
    "\n",
    "command = (\n",
    "    f\"accelerate launch train_text_to_image_lora.py \"\n",
    "    f\"--adam_beta1={merged_config['adam_beta1']} \"\n",
    "    f\"--adam_beta2={merged_config['adam_beta2']} \"\n",
    "    f\"--adam_epsilon={merged_config['adam_epsilon']} \"\n",
    "    f\"--adam_weight_decay={merged_config['adam_weight_decay']} \"\n",
    "    f\"--caption_column={merged_config['caption_column']} \"\n",
    "    f\"--center_crop \"\n",
    "    f\"--checkpointing_steps={merged_config['checkpointing_steps']} \"\n",
    "    f\"--dataloader_num_workers={merged_config['dataloader_num_workers']} \"\n",
    "    f\"--dataset_name={merged_config['dataset_name']} \"\n",
    "    f\"--gradient_accumulation_steps={merged_config['gradient_accumulation_steps']} \"\n",
    "    f\"--image_column={merged_config['image_column']} \"\n",
    "    f\"--learning_rate={merged_config['learning_rate']} \"\n",
    "    f\"--local_rank={merged_config['local_rank']} \"\n",
    "    f\"--logging_dir={merged_config['logging_dir']} \"\n",
    "    f\"--lr_scheduler={merged_config['lr_scheduler']} \"\n",
    "    f\"--lr_warmup_steps={merged_config['lr_warmup_steps']} \"\n",
    "    f\"--max_grad_norm={merged_config['max_grad_norm']} \"\n",
    "    f\"--max_train_steps={merged_config['max_train_steps']} \"\n",
    "    f\"--mixed_precision={merged_config['mixed_precision']} \"\n",
    "    f\"--noise_offset={merged_config['noise_offset']} \"\n",
    "    f\"--num_train_epochs={merged_config['num_train_epochs']} \"\n",
    "    f\"--num_validation_images={merged_config['num_validation_images']} \"\n",
    "    f\"--output_dir={merged_config['output_dir']} \"\n",
    "    f\"--pretrained_model_name_or_path={merged_config['pretrained_model_name_or_path']} \"\n",
    "    f\"--rank={merged_config['rank']} \"\n",
    "    f\"--report_to={merged_config['report_to']} \"\n",
    "    f\"--resolution={merged_config['resolution']} \"\n",
    "    f\"--resume_from_checkpoint='latest' \"\n",
    "    f\"--seed={merged_config['seed']} \"\n",
    "    f\"--train_batch_size={merged_config['train_batch_size']} \"\n",
    "    f\"--validation_epochs={merged_config['validation_epochs']} \"\n",
    "    f\"--validation_prompt=\\\"{merged_config['validation_prompt']}\\\" \" # Properly quote the validation prompt\n",
    "    f\"--validation_negative_prompt=\\\"{merged_config['validation_negative_prompt']}\\\" \" # Properly quote the negative prompt\n",
    ")\n",
    "\n",
    "for arg in optional_args:\n",
    "    if merged_config[arg] is not None:\n",
    "        command += f\" --{arg}={merged_config[arg]}\"\n",
    "\n",
    "boolean_flags = [\n",
    "    'allow_tf32', 'enable_xformers_memory_efficient_attention', 'push_to_hub', 'random_flip',\n",
    "    'gradient_checkpointing', 'scale_lr', 'use_8bit_adam'\n",
    "]\n",
    "\n",
    "for flag in boolean_flags:\n",
    "    if merged_config[flag]:\n",
    "        command += f\" --{flag}\"\n",
    "\n",
    "os.system(command)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-09T05:49:40.764023Z",
     "start_time": "2024-06-09T04:20:02.369135Z"
    }
   },
   "id": "7bc8fa0fbf40392b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_processes` was set to a value of `1`\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--mixed_precision` was set to a value of `'no'`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "06/09/2024 06:20:04 - INFO - __main__ - Distributed environment: NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: bf16\n",
      "\n",
      "06/09/2024 06:20:05 - WARNING - __main__ - Failed to load EulerAncestralDiscreteScheduler: stabilityai/stable-diffusion-2-1 does not appear to have a file named scheduler_config.json.\n",
      "06/09/2024 06:20:05 - INFO - __main__ - Using customized DDIMScheduler with clip_sample set to False.\n",
      "{'latents_std', 'force_upcast', 'scaling_factor', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
      "{'transformer_layers_per_block', 'cross_attention_norm', 'class_embed_type', 'reverse_transformer_layers_per_block', 'addition_embed_type_num_heads', 'conv_in_kernel', 'class_embeddings_concat', 'time_embedding_dim', 'resnet_skip_time_act', 'encoder_hid_dim_type', 'conv_out_kernel', 'num_attention_heads', 'dropout', 'timestep_post_act', 'projection_class_embeddings_input_dim', 'time_embedding_act_fn', 'time_cond_proj_dim', 'attention_type', 'encoder_hid_dim', 'mid_block_only_cross_attention', 'time_embedding_type', 'resnet_out_scale_factor', 'resnet_time_scale_shift', 'addition_embed_type', 'addition_time_embed_dim', 'mid_block_type'} was not found in config. Values will be initialized to default values.\n",
      "06/09/2024 06:20:12 - INFO - __main__ - ***** Running training *****\n",
      "06/09/2024 06:20:12 - INFO - __main__ -   Num examples = 803\n",
      "06/09/2024 06:20:12 - INFO - __main__ -   Num Epochs = 20\n",
      "06/09/2024 06:20:12 - INFO - __main__ -   Instantaneous batch size per device = 2\n",
      "06/09/2024 06:20:12 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "06/09/2024 06:20:12 - INFO - __main__ -   Gradient Accumulation steps = 8\n",
      "06/09/2024 06:20:12 - INFO - __main__ -   Total optimization steps = 1000\n",
      "06/09/2024 06:20:12 - INFO - accelerate.accelerator - Loading states from logo_lora/checkpoint-500\n",
      "06/09/2024 06:20:13 - INFO - accelerate.checkpointing - All model weights loaded successfully\n",
      "06/09/2024 06:20:13 - INFO - accelerate.checkpointing - All optimizer states loaded successfully\n",
      "06/09/2024 06:20:13 - INFO - accelerate.checkpointing - All scheduler states loaded successfully\n",
      "06/09/2024 06:20:13 - INFO - accelerate.checkpointing - All dataloader sampler states loaded successfully\n",
      "06/09/2024 06:20:13 - INFO - accelerate.checkpointing - All random states loaded successfully\n",
      "06/09/2024 06:20:13 - INFO - accelerate.accelerator - Loading in 0 custom states\n",
      "Steps:  55%|█████▌    | 551/1000 [08:41<59:23,  7.94s/it, lr=1.1e-5, step_loss=0.558]06/09/2024 06:28:54 - INFO - __main__ - Running validation... \n",
      " Generating 2 images with prompt: a logo of coffee shop, image of a filled cup with steam, white background, black, darkgray foreground, modern, minimalism, vector art, 2d, best quality, centered and negative prompt: low quality, worst quality, bad composition, extra digit, fewer digits, text, inscription, watermark, label, asymmetric.\n",
      "06/09/2024 06:28:54 - WARNING - __main__ - Failed to load EulerAncestralDiscreteScheduler: stabilityai/stable-diffusion-2-1 does not appear to have a file named scheduler_config.json.\n",
      "06/09/2024 06:28:54 - INFO - __main__ - Using customized DDIMScheduler with clip_sample set to False.\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]\u001B[A{'latents_std', 'force_upcast', 'scaling_factor', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "\n",
      "Loading pipeline components...:  17%|█▋        | 1/6 [00:00<00:00,  5.83it/s]\u001B[ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "\n",
      "Loading pipeline components...: 100%|██████████| 6/6 [00:00<00:00,  8.94it/s]\u001B[A\n",
      "/home/user/PycharmProjects/LogoLora/venv/lib/python3.10/site-packages/diffusers/image_processor.py:92: RuntimeWarning: invalid value encountered in cast\n",
      "  images = (images * 255).round().astype(\"uint8\")\n",
      "Steps:  60%|██████    | 602/1000 [17:43<52:29,  7.91s/it, lr=1.2e-5, step_loss=0.45] 06/09/2024 06:37:56 - INFO - __main__ - Running validation... \n",
      " Generating 2 images with prompt: a logo of coffee shop, image of a filled cup with steam, white background, black, darkgray foreground, modern, minimalism, vector art, 2d, best quality, centered and negative prompt: low quality, worst quality, bad composition, extra digit, fewer digits, text, inscription, watermark, label, asymmetric.\n",
      "06/09/2024 06:37:56 - WARNING - __main__ - Failed to load EulerAncestralDiscreteScheduler: stabilityai/stable-diffusion-2-1 does not appear to have a file named scheduler_config.json.\n",
      "06/09/2024 06:37:56 - INFO - __main__ - Using customized DDIMScheduler with clip_sample set to False.\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]\u001B[A{'latents_std', 'force_upcast', 'scaling_factor', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "\n",
      "Loading pipeline components...:  50%|█████     | 3/6 [00:00<00:00, 23.91it/s]\u001B[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "\n",
      "Loading pipeline components...: 100%|██████████| 6/6 [00:00<00:00, 11.66it/s]\u001B[A\n",
      "Steps:  65%|██████▌   | 653/1000 [26:44<45:43,  7.91s/it, lr=1.31e-5, step_loss=0.159]06/09/2024 06:46:57 - INFO - __main__ - Running validation... \n",
      " Generating 2 images with prompt: a logo of coffee shop, image of a filled cup with steam, white background, black, darkgray foreground, modern, minimalism, vector art, 2d, best quality, centered and negative prompt: low quality, worst quality, bad composition, extra digit, fewer digits, text, inscription, watermark, label, asymmetric.\n",
      "06/09/2024 06:46:58 - WARNING - __main__ - Failed to load EulerAncestralDiscreteScheduler: stabilityai/stable-diffusion-2-1 does not appear to have a file named scheduler_config.json.\n",
      "06/09/2024 06:46:58 - INFO - __main__ - Using customized DDIMScheduler with clip_sample set to False.\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]\u001B[A{'latents_std', 'force_upcast', 'scaling_factor', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "\n",
      "Loading pipeline components...:  50%|█████     | 3/6 [00:00<00:00, 15.19it/s]\u001B[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "\n",
      "Loading pipeline components...: 100%|██████████| 6/6 [00:00<00:00, 10.60it/s]\u001B[A\n",
      "Steps:  70%|███████   | 704/1000 [35:45<39:00,  7.91s/it, lr=1.41e-5, step_loss=0.157]06/09/2024 06:55:59 - INFO - __main__ - Running validation... \n",
      " Generating 2 images with prompt: a logo of coffee shop, image of a filled cup with steam, white background, black, darkgray foreground, modern, minimalism, vector art, 2d, best quality, centered and negative prompt: low quality, worst quality, bad composition, extra digit, fewer digits, text, inscription, watermark, label, asymmetric.\n",
      "06/09/2024 06:55:59 - WARNING - __main__ - Failed to load EulerAncestralDiscreteScheduler: stabilityai/stable-diffusion-2-1 does not appear to have a file named scheduler_config.json.\n",
      "06/09/2024 06:55:59 - INFO - __main__ - Using customized DDIMScheduler with clip_sample set to False.\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]\u001B[A{'latents_std', 'force_upcast', 'scaling_factor', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "\n",
      "Loading pipeline components...:  50%|█████     | 3/6 [00:00<00:00, 15.13it/s]\u001B[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "\n",
      "Loading pipeline components...: 100%|██████████| 6/6 [00:00<00:00, 10.60it/s]\u001B[A\n",
      "Steps:  76%|███████▌  | 755/1000 [44:47<32:16,  7.90s/it, lr=1.51e-5, step_loss=0.206]06/09/2024 07:05:00 - INFO - __main__ - Running validation... \n",
      " Generating 2 images with prompt: a logo of coffee shop, image of a filled cup with steam, white background, black, darkgray foreground, modern, minimalism, vector art, 2d, best quality, centered and negative prompt: low quality, worst quality, bad composition, extra digit, fewer digits, text, inscription, watermark, label, asymmetric.\n",
      "06/09/2024 07:05:01 - WARNING - __main__ - Failed to load EulerAncestralDiscreteScheduler: stabilityai/stable-diffusion-2-1 does not appear to have a file named scheduler_config.json.\n",
      "06/09/2024 07:05:01 - INFO - __main__ - Using customized DDIMScheduler with clip_sample set to False.\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]\u001B[A{'latents_std', 'force_upcast', 'scaling_factor', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "\n",
      "Loading pipeline components...:  50%|█████     | 3/6 [00:00<00:00, 15.37it/s]\u001B[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "\n",
      "Loading pipeline components...: 100%|██████████| 6/6 [00:00<00:00, 10.66it/s]\u001B[A\n",
      "Steps:  81%|████████  | 806/1000 [53:49<25:34,  7.91s/it, lr=1.61e-5, step_loss=0.0836]06/09/2024 07:14:02 - INFO - __main__ - Running validation... \n",
      " Generating 2 images with prompt: a logo of coffee shop, image of a filled cup with steam, white background, black, darkgray foreground, modern, minimalism, vector art, 2d, best quality, centered and negative prompt: low quality, worst quality, bad composition, extra digit, fewer digits, text, inscription, watermark, label, asymmetric.\n",
      "06/09/2024 07:14:02 - WARNING - __main__ - Failed to load EulerAncestralDiscreteScheduler: stabilityai/stable-diffusion-2-1 does not appear to have a file named scheduler_config.json.\n",
      "06/09/2024 07:14:02 - INFO - __main__ - Using customized DDIMScheduler with clip_sample set to False.\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]\u001B[A{'latents_std', 'force_upcast', 'scaling_factor', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "\n",
      "Loading pipeline components...:  50%|█████     | 3/6 [00:00<00:00, 15.14it/s]\u001B[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "\n",
      "Loading pipeline components...: 100%|██████████| 6/6 [00:00<00:00, 10.59it/s]\u001B[A\n",
      "Steps:  86%|████████▌ | 857/1000 [1:02:50<18:51,  7.91s/it, lr=1.71e-5, step_loss=0.166]06/09/2024 07:23:03 - INFO - __main__ - Running validation... \n",
      " Generating 2 images with prompt: a logo of coffee shop, image of a filled cup with steam, white background, black, darkgray foreground, modern, minimalism, vector art, 2d, best quality, centered and negative prompt: low quality, worst quality, bad composition, extra digit, fewer digits, text, inscription, watermark, label, asymmetric.\n",
      "06/09/2024 07:23:04 - WARNING - __main__ - Failed to load EulerAncestralDiscreteScheduler: stabilityai/stable-diffusion-2-1 does not appear to have a file named scheduler_config.json.\n",
      "06/09/2024 07:23:04 - INFO - __main__ - Using customized DDIMScheduler with clip_sample set to False.\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]\u001B[A{'latents_std', 'force_upcast', 'scaling_factor', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "\n",
      "Loading pipeline components...:  50%|█████     | 3/6 [00:00<00:00, 15.01it/s]\u001B[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "\n",
      "Loading pipeline components...: 100%|██████████| 6/6 [00:00<00:00, 10.53it/s]\u001B[A\n",
      "Steps:  91%|█████████ | 908/1000 [1:11:52<12:07,  7.91s/it, lr=1.82e-5, step_loss=0.122] 06/09/2024 07:32:05 - INFO - __main__ - Running validation... \n",
      " Generating 2 images with prompt: a logo of coffee shop, image of a filled cup with steam, white background, black, darkgray foreground, modern, minimalism, vector art, 2d, best quality, centered and negative prompt: low quality, worst quality, bad composition, extra digit, fewer digits, text, inscription, watermark, label, asymmetric.\n",
      "06/09/2024 07:32:05 - WARNING - __main__ - Failed to load EulerAncestralDiscreteScheduler: stabilityai/stable-diffusion-2-1 does not appear to have a file named scheduler_config.json.\n",
      "06/09/2024 07:32:05 - INFO - __main__ - Using customized DDIMScheduler with clip_sample set to False.\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]\u001B[A{'latents_std', 'force_upcast', 'scaling_factor', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "\n",
      "Loading pipeline components...:  50%|█████     | 3/6 [00:00<00:00, 15.19it/s]\u001B[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "\n",
      "Loading pipeline components...: 100%|██████████| 6/6 [00:00<00:00, 10.56it/s]\u001B[A\n",
      "Steps:  96%|█████████▌| 959/1000 [1:20:53<05:24,  7.91s/it, lr=1.92e-5, step_loss=0.117] 06/09/2024 07:41:06 - INFO - __main__ - Running validation... \n",
      " Generating 2 images with prompt: a logo of coffee shop, image of a filled cup with steam, white background, black, darkgray foreground, modern, minimalism, vector art, 2d, best quality, centered and negative prompt: low quality, worst quality, bad composition, extra digit, fewer digits, text, inscription, watermark, label, asymmetric.\n",
      "06/09/2024 07:41:06 - WARNING - __main__ - Failed to load EulerAncestralDiscreteScheduler: stabilityai/stable-diffusion-2-1 does not appear to have a file named scheduler_config.json.\n",
      "06/09/2024 07:41:06 - INFO - __main__ - Using customized DDIMScheduler with clip_sample set to False.\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]\u001B[A{'latents_std', 'force_upcast', 'scaling_factor', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "\n",
      "Loading pipeline components...:  50%|█████     | 3/6 [00:00<00:00, 14.97it/s]\u001B[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "\n",
      "Loading pipeline components...: 100%|██████████| 6/6 [00:00<00:00, 10.59it/s]\u001B[A\n",
      "Steps: 100%|██████████| 1000/1000 [1:28:19<00:00, 10.37s/it, lr=2e-5, step_loss=0.0506]06/09/2024 07:48:32 - INFO - accelerate.accelerator - Saving current state to logo_lora/checkpoint-1000\n",
      "06/09/2024 07:48:34 - INFO - accelerate.checkpointing - Model weights saved in logo_lora/checkpoint-1000/model.safetensors\n",
      "06/09/2024 07:48:34 - INFO - accelerate.checkpointing - Optimizer state saved in logo_lora/checkpoint-1000/optimizer.bin\n",
      "06/09/2024 07:48:34 - INFO - accelerate.checkpointing - Scheduler state saved in logo_lora/checkpoint-1000/scheduler.bin\n",
      "06/09/2024 07:48:34 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in logo_lora/checkpoint-1000/sampler.bin\n",
      "06/09/2024 07:48:34 - INFO - accelerate.checkpointing - Random states saved in logo_lora/checkpoint-1000/random_states_0.pkl\n",
      "Model weights saved in logo_lora/checkpoint-1000/pytorch_lora_weights.safetensors\n",
      "06/09/2024 07:48:34 - INFO - __main__ - Saved state to logo_lora/checkpoint-1000\n",
      "Steps: 100%|██████████| 1000/1000 [1:28:21<00:00, 10.37s/it, lr=2e-5, step_loss=0.137] 06/09/2024 07:48:34 - INFO - __main__ - Running validation... \n",
      " Generating 2 images with prompt: a logo of coffee shop, image of a filled cup with steam, white background, black, darkgray foreground, modern, minimalism, vector art, 2d, best quality, centered and negative prompt: low quality, worst quality, bad composition, extra digit, fewer digits, text, inscription, watermark, label, asymmetric.\n",
      "06/09/2024 07:48:35 - WARNING - __main__ - Failed to load EulerAncestralDiscreteScheduler: stabilityai/stable-diffusion-2-1 does not appear to have a file named scheduler_config.json.\n",
      "06/09/2024 07:48:35 - INFO - __main__ - Using customized DDIMScheduler with clip_sample set to False.\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]\u001B[A{'latents_std', 'force_upcast', 'scaling_factor', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "\n",
      "Loading pipeline components...:  50%|█████     | 3/6 [00:00<00:00, 29.96it/s]\u001B[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "\n",
      "Loading pipeline components...: 100%|██████████| 6/6 [00:00<00:00, 13.90it/s]\u001B[A\n",
      "Steps: 100%|██████████| 1000/1000 [1:28:43<00:00, 10.37s/it, lr=2e-5, step_loss=0.0773]06/09/2024 07:48:56 - INFO - __main__ - Running validation... \n",
      " Generating 2 images with prompt: a logo of coffee shop, image of a filled cup with steam, white background, black, darkgray foreground, modern, minimalism, vector art, 2d, best quality, centered and negative prompt: low quality, worst quality, bad composition, extra digit, fewer digits, text, inscription, watermark, label, asymmetric.\n",
      "06/09/2024 07:48:56 - WARNING - __main__ - Failed to load EulerAncestralDiscreteScheduler: stabilityai/stable-diffusion-2-1 does not appear to have a file named scheduler_config.json.\n",
      "06/09/2024 07:48:56 - INFO - __main__ - Using customized DDIMScheduler with clip_sample set to False.\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]\u001B[A{'latents_std', 'force_upcast', 'scaling_factor', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "\n",
      "Loading pipeline components...:  50%|█████     | 3/6 [00:00<00:00, 25.49it/s]\u001B[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "\n",
      "Loading pipeline components...: 100%|██████████| 6/6 [00:00<00:00, 12.31it/s]\u001B[A\n",
      "Model weights saved in logo_lora/pytorch_lora_weights.safetensors\n",
      "{'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]\u001B[A{'latents_std', 'force_upcast', 'scaling_factor', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "{'timestep_spacing', 'dynamic_thresholding_ratio', 'clip_sample_range', 'thresholding', 'rescale_betas_zero_snr', 'sample_max_value'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DDIMScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "\n",
      "Loading pipeline components...:  83%|████████▎ | 5/6 [00:00<00:00, 12.57it/s]\u001B[A{'transformer_layers_per_block', 'cross_attention_norm', 'class_embed_type', 'reverse_transformer_layers_per_block', 'addition_embed_type_num_heads', 'conv_in_kernel', 'class_embeddings_concat', 'time_embedding_dim', 'resnet_skip_time_act', 'encoder_hid_dim_type', 'conv_out_kernel', 'num_attention_heads', 'dropout', 'timestep_post_act', 'projection_class_embeddings_input_dim', 'time_embedding_act_fn', 'time_cond_proj_dim', 'attention_type', 'encoder_hid_dim', 'mid_block_only_cross_attention', 'time_embedding_type', 'resnet_out_scale_factor', 'resnet_time_scale_shift', 'addition_embed_type', 'addition_time_embed_dim', 'mid_block_type'} was not found in config. Values will be initialized to default values.\n",
      "Loaded unet as UNet2DConditionModel from `unet` subfolder of stabilityai/stable-diffusion-2-1.\n",
      "Loading pipeline components...: 100%|██████████| 6/6 [00:01<00:00,  3.31it/s]\n",
      "Loading unet.\n",
      "\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]\u001B[A\n",
      "  3%|▎         | 1/30 [00:00<00:09,  2.97it/s]\u001B[A\n",
      "  7%|▋         | 2/30 [00:00<00:09,  3.07it/s]\u001B[A\n",
      " 10%|█         | 3/30 [00:00<00:08,  3.10it/s]\u001B[A\n",
      " 13%|█▎        | 4/30 [00:01<00:08,  3.11it/s]\u001B[A\n",
      " 17%|█▋        | 5/30 [00:01<00:08,  3.12it/s]\u001B[A\n",
      " 20%|██        | 6/30 [00:01<00:07,  3.12it/s]\u001B[A\n",
      " 23%|██▎       | 7/30 [00:02<00:07,  3.13it/s]\u001B[A\n",
      " 27%|██▋       | 8/30 [00:02<00:07,  3.13it/s]\u001B[A\n",
      " 30%|███       | 9/30 [00:02<00:06,  3.13it/s]\u001B[A\n",
      " 33%|███▎      | 10/30 [00:03<00:06,  3.13it/s]\u001B[A\n",
      " 37%|███▋      | 11/30 [00:03<00:06,  3.13it/s]\u001B[A\n",
      " 40%|████      | 12/30 [00:03<00:05,  3.13it/s]\u001B[A\n",
      " 43%|████▎     | 13/30 [00:04<00:05,  3.13it/s]\u001B[A\n",
      " 47%|████▋     | 14/30 [00:04<00:05,  3.13it/s]\u001B[A\n",
      " 50%|█████     | 15/30 [00:04<00:04,  3.13it/s]\u001B[A\n",
      " 53%|█████▎    | 16/30 [00:05<00:04,  3.13it/s]\u001B[A\n",
      " 57%|█████▋    | 17/30 [00:05<00:04,  3.13it/s]\u001B[A\n",
      " 60%|██████    | 18/30 [00:05<00:03,  3.13it/s]\u001B[A\n",
      " 63%|██████▎   | 19/30 [00:06<00:03,  3.13it/s]\u001B[A\n",
      " 67%|██████▋   | 20/30 [00:06<00:03,  3.13it/s]\u001B[A\n",
      " 70%|███████   | 21/30 [00:06<00:02,  3.13it/s]\u001B[A\n",
      " 73%|███████▎  | 22/30 [00:07<00:02,  3.13it/s]\u001B[A\n",
      " 77%|███████▋  | 23/30 [00:07<00:02,  3.13it/s]\u001B[A\n",
      " 80%|████████  | 24/30 [00:07<00:01,  3.13it/s]\u001B[A\n",
      " 83%|████████▎ | 25/30 [00:07<00:01,  3.13it/s]\u001B[A\n",
      " 87%|████████▋ | 26/30 [00:08<00:01,  3.13it/s]\u001B[A\n",
      " 90%|█████████ | 27/30 [00:08<00:00,  3.13it/s]\u001B[A\n",
      " 93%|█████████▎| 28/30 [00:08<00:00,  3.13it/s]\u001B[A\n",
      " 97%|█████████▋| 29/30 [00:09<00:00,  3.13it/s]\u001B[A\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.13it/s]\u001B[A\n",
      "\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]\u001B[A\n",
      "  3%|▎         | 1/30 [00:00<00:09,  3.13it/s]\u001B[A\n",
      "  7%|▋         | 2/30 [00:00<00:08,  3.13it/s]\u001B[A\n",
      " 10%|█         | 3/30 [00:00<00:08,  3.13it/s]\u001B[A\n",
      " 13%|█▎        | 4/30 [00:01<00:08,  3.13it/s]\u001B[A\n",
      " 17%|█▋        | 5/30 [00:01<00:07,  3.13it/s]\u001B[A\n",
      " 20%|██        | 6/30 [00:01<00:07,  3.13it/s]\u001B[A\n",
      " 23%|██▎       | 7/30 [00:02<00:07,  3.13it/s]\u001B[A\n",
      " 27%|██▋       | 8/30 [00:02<00:07,  3.13it/s]\u001B[A\n",
      " 30%|███       | 9/30 [00:02<00:06,  3.13it/s]\u001B[A\n",
      " 33%|███▎      | 10/30 [00:03<00:06,  3.13it/s]\u001B[A\n",
      " 37%|███▋      | 11/30 [00:03<00:06,  3.13it/s]\u001B[A\n",
      " 40%|████      | 12/30 [00:03<00:05,  3.13it/s]\u001B[A\n",
      " 43%|████▎     | 13/30 [00:04<00:05,  3.13it/s]\u001B[A\n",
      " 47%|████▋     | 14/30 [00:04<00:05,  3.13it/s]\u001B[A\n",
      " 50%|█████     | 15/30 [00:04<00:04,  3.13it/s]\u001B[A\n",
      " 53%|█████▎    | 16/30 [00:05<00:04,  3.13it/s]\u001B[A\n",
      " 57%|█████▋    | 17/30 [00:05<00:04,  3.13it/s]\u001B[A\n",
      " 60%|██████    | 18/30 [00:05<00:03,  3.13it/s]\u001B[A\n",
      " 63%|██████▎   | 19/30 [00:06<00:03,  3.13it/s]\u001B[A\n",
      " 67%|██████▋   | 20/30 [00:06<00:03,  3.13it/s]\u001B[A\n",
      " 70%|███████   | 21/30 [00:06<00:02,  3.13it/s]\u001B[A\n",
      " 73%|███████▎  | 22/30 [00:07<00:02,  3.13it/s]\u001B[A\n",
      " 77%|███████▋  | 23/30 [00:07<00:02,  3.13it/s]\u001B[A\n",
      " 80%|████████  | 24/30 [00:07<00:01,  3.13it/s]\u001B[A\n",
      " 83%|████████▎ | 25/30 [00:07<00:01,  3.13it/s]\u001B[A\n",
      " 87%|████████▋ | 26/30 [00:08<00:01,  3.13it/s]\u001B[A\n",
      " 90%|█████████ | 27/30 [00:08<00:00,  3.13it/s]\u001B[A\n",
      " 93%|█████████▎| 28/30 [00:08<00:00,  3.13it/s]\u001B[A\n",
      " 97%|█████████▋| 29/30 [00:09<00:00,  3.13it/s]\u001B[A\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.13it/s]\u001B[A\n",
      "Steps: 100%|██████████| 1000/1000 [1:29:26<00:00, 10.73s/it, lr=2e-5, step_loss=0.0773]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
